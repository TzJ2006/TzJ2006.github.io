<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Bug Journal 2025-06-09 | TzJ&#39;s Net</title>
<meta name="keywords" content="Bug Journal">
<meta name="description" content="Robo-DM: Data Management For Large Robot Datasets
ICRA 2025 BestPaper on Robot Learning
from UCB &amp; Google Deepmind
做数据库的

以前的数据都没压缩过，太大了; 存储，传输成本也高
这样的话加载也会很慢


这是新的数据库格式，在兼容当前格式的情况下尽量做到了最小
他存储成了统一的数据格式；可以通过内存访问；可以顺序/随机访问；有模块化设计

最后把信息都通过 EBML file 存储
为什么选择 EBML 呢?
因为：

支持嵌套结构
是自包含的，更方便复用
支持流处理，不需要一次性全部导入到内存中
支持自动时间同步

对于视频，主要选择了.H264 来压缩，显著降低了文件大小


最后这个数据集又小又快


Achieving Human Level Competitive Robot Table Tennis: A Comprehensive Overview
ICRA 2025 Best Paper on Robot Learning Finalist
from Google Deepmind
机器人打乒乓球
打乒乓球要又快又准。所以是理想的机器人测试器
对于这个机器人，用上了 模仿学习 &#43; 强化学习 &#43; 分层控制 &#43; Continue Learning">
<meta name="author" content="">
<link rel="canonical" href="https://tzj2006.github.io/bugjournal/2025-06-09/">

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
  <meta name="referrer" content="no-referrer-when-downgrade">
<link crossorigin="anonymous" href="https://tzj2006.github.io/assets/css/stylesheet.af858c2feef42adc7846f815c3e21de9982d82f8fc4f65879451b2686859975a.css" integrity="sha256-r4WML&#43;70Ktx4RvgVw&#43;Id6Zgtgvj8T2WHlFGyaGhZl1o=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://tzj2006.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://tzj2006.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://tzj2006.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://tzj2006.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://tzj2006.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://tzj2006.github.io/bugjournal/2025-06-09/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>

<script type="text/javascript" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>


<script src="https://tzj2006.github.io/js/checkbox-state.min.481208bf28be32dd7419d90065130144ba9a464a94857de0dc07fd19d3f2f6f3.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous">

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js" integrity="sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY" crossorigin="anonymous"></script>

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js" integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>


<script>
document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "$", right: "$", display: false}
        ]
    });
});
</script>
<meta property="og:url" content="https://tzj2006.github.io/bugjournal/2025-06-09/">
  <meta property="og:site_name" content="TzJ&#39;s Net">
  <meta property="og:title" content="Bug Journal 2025-06-09">
  <meta property="og:description" content="Robo-DM: Data Management For Large Robot Datasets ICRA 2025 BestPaper on Robot Learning
from UCB &amp; Google Deepmind
做数据库的
以前的数据都没压缩过，太大了; 存储，传输成本也高 这样的话加载也会很慢 这是新的数据库格式，在兼容当前格式的情况下尽量做到了最小
他存储成了统一的数据格式；可以通过内存访问；可以顺序/随机访问；有模块化设计
最后把信息都通过 EBML file 存储
为什么选择 EBML 呢?
因为：
支持嵌套结构 是自包含的，更方便复用 支持流处理，不需要一次性全部导入到内存中 支持自动时间同步 对于视频，主要选择了.H264 来压缩，显著降低了文件大小
最后这个数据集又小又快
Achieving Human Level Competitive Robot Table Tennis: A Comprehensive Overview ICRA 2025 Best Paper on Robot Learning Finalist
from Google Deepmind
机器人打乒乓球
打乒乓球要又快又准。所以是理想的机器人测试器
对于这个机器人，用上了 模仿学习 &#43; 强化学习 &#43; 分层控制 &#43; Continue Learning">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="bugjournal">
    <meta property="article:published_time" content="2025-06-09T11:36:45+08:00">
    <meta property="article:modified_time" content="2025-06-09T11:36:45+08:00">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Bug Journal 2025-06-09">
<meta name="twitter:description" content="Robo-DM: Data Management For Large Robot Datasets
ICRA 2025 BestPaper on Robot Learning
from UCB &amp; Google Deepmind
做数据库的

以前的数据都没压缩过，太大了; 存储，传输成本也高
这样的话加载也会很慢


这是新的数据库格式，在兼容当前格式的情况下尽量做到了最小
他存储成了统一的数据格式；可以通过内存访问；可以顺序/随机访问；有模块化设计

最后把信息都通过 EBML file 存储
为什么选择 EBML 呢?
因为：

支持嵌套结构
是自包含的，更方便复用
支持流处理，不需要一次性全部导入到内存中
支持自动时间同步

对于视频，主要选择了.H264 来压缩，显著降低了文件大小


最后这个数据集又小又快


Achieving Human Level Competitive Robot Table Tennis: A Comprehensive Overview
ICRA 2025 Best Paper on Robot Learning Finalist
from Google Deepmind
机器人打乒乓球
打乒乓球要又快又准。所以是理想的机器人测试器
对于这个机器人，用上了 模仿学习 &#43; 强化学习 &#43; 分层控制 &#43; Continue Learning">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "BugJournals",
      "item": "https://tzj2006.github.io/bugjournal/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Bug Journal 2025-06-09",
      "item": "https://tzj2006.github.io/bugjournal/2025-06-09/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Bug Journal 2025-06-09",
  "name": "Bug Journal 2025-06-09",
  "description": "Robo-DM: Data Management For Large Robot Datasets ICRA 2025 BestPaper on Robot Learning\nfrom UCB \u0026amp; Google Deepmind\n做数据库的\n以前的数据都没压缩过，太大了; 存储，传输成本也高 这样的话加载也会很慢 这是新的数据库格式，在兼容当前格式的情况下尽量做到了最小\n他存储成了统一的数据格式；可以通过内存访问；可以顺序/随机访问；有模块化设计\n最后把信息都通过 EBML file 存储\n为什么选择 EBML 呢?\n因为：\n支持嵌套结构 是自包含的，更方便复用 支持流处理，不需要一次性全部导入到内存中 支持自动时间同步 对于视频，主要选择了.H264 来压缩，显著降低了文件大小\n最后这个数据集又小又快\nAchieving Human Level Competitive Robot Table Tennis: A Comprehensive Overview ICRA 2025 Best Paper on Robot Learning Finalist\nfrom Google Deepmind\n机器人打乒乓球\n打乒乓球要又快又准。所以是理想的机器人测试器\n对于这个机器人，用上了 模仿学习 + 强化学习 + 分层控制 + Continue Learning\n",
  "keywords": [
    "Bug Journal"
  ],
  "articleBody": "Robo-DM: Data Management For Large Robot Datasets ICRA 2025 BestPaper on Robot Learning\nfrom UCB \u0026 Google Deepmind\n做数据库的\n以前的数据都没压缩过，太大了; 存储，传输成本也高 这样的话加载也会很慢 这是新的数据库格式，在兼容当前格式的情况下尽量做到了最小\n他存储成了统一的数据格式；可以通过内存访问；可以顺序/随机访问；有模块化设计\n最后把信息都通过 EBML file 存储\n为什么选择 EBML 呢?\n因为：\n支持嵌套结构 是自包含的，更方便复用 支持流处理，不需要一次性全部导入到内存中 支持自动时间同步 对于视频，主要选择了.H264 来压缩，显著降低了文件大小\n最后这个数据集又小又快\nAchieving Human Level Competitive Robot Table Tennis: A Comprehensive Overview ICRA 2025 Best Paper on Robot Learning Finalist\nfrom Google Deepmind\n机器人打乒乓球\n打乒乓球要又快又准。所以是理想的机器人测试器\n对于这个机器人，用上了 模仿学习 + 强化学习 + 分层控制 + Continue Learning\n首先用模仿学习做 base, 然后强化学习训练\n分层控制则是类似 MOE 的思路，每一个子网络都“学一种打球技术”\n然后让主网络来“选择一种打球技术”。\n控制频率：50HZ.\n并且主网络还会在 Validation 的时候 Continue Learning\n比喻：当机器人发现正手比反手好得分，那机器人就会偏向于打更多正手\n$H(s, a) = H_{offline}(s, a) + \\alpha * [R(s, a) - R_{expected}(s, a)]$\n在这里，$H(s,a)$ 是现在的偏好 $H_{offline}(s,a)$ 是训练时的偏好 $R(s,a)$ 是当前环境的奖励 $R_{expected}$ 是预期获得的奖励\n结果：\n此处，B 指 Beginner, I 指 Intermediate, A 指 Expert\n训练难度：\n2.4 Billion steps on 6k Parallel Simulators 训练出了正反手\n每一个操作需要训练 300 - 1200 Million Steps.\n但是推理难度很低，只需要一个 CPU 的 3ms CPU time 即可完成\n最终能实现 50Hz 的推理速度\nNo Plan but Everything Under Control: Robustly Solving Sequential Tasks with Dynamically Composed Gradient Descent ICRA 2025 Best Paper on robot learning finalist\nFrom University of Berlin\n部分现有方法用的是 planning 来做的机器人 manipultaion task.\n就是说比如会找到一个机器人的起点和终点，然后通过一些算法从起点移动到终点\n这样的算法会通过一些数据来训练\n但是人类在做这些 task 的时候并不会有一个 planning, 那如何不训练做这些 task 呢？\n既然现在 Gradient Descent 这么强，能不能考虑直接用 Gradient Desent 来解决这个问题呢？\n可以的：但是和传统的 Gradient Desnet 不一样的点在于：传统的 Gradient Desent 会把所有的 Gradient 全部加在一起，但是对于现在的 task, 不一定要找全局最优解，可以找当前“做哪个分解动作”最优。\n比如：现在可以让机械臂向某个轴的某个方向移动，或者让机械臂把物品抓起来。\n缺点：这个方法必须要对于每一个 task 都设计一个新的 Gradient 方向。\n优点：这个方法可以避免一些不必要的移动，并且可以根据当前状态来调整他的策略。\n实验设计：在“block world”模拟环境中和现实中推拉抽屉。\n在现实世界中会对于这个环境给予一个 干扰，看看这个模型的抗干扰能力如何。\n比较的模型是：ICRA 2020: Online replanning in belief space for partially observable task and motion problems\nPolyTouch: A Robust Multi-Modal Tactile Sensor for Contact-rich Manipulation ICRA 2025 Best Paper in Field and Service Robotics\n使用了多种 Modality 来增强模型的 Manipulation 能力\n使用了包括：视觉，听觉，触觉 … 等 modality 的能力\n实验设计：\n耐用性 成功率 首先和一个其他的商业模型做对比，然后发现耐用性更高\n然后和自己做消融实验做对比，然后发现模态越多，效果越好\nHuman-Agent Joint Learning for Efficient Robot Manipulation Skill Acquisition ICRA 2025 Best Paper on Human-Robot Interaction\nFrom 上交 \u0026 UIUC\n提出了一种更高效的数据收集 \u0026 训练的方式\n核心在于 Diffusion Policy 的应用。\n最开始的时候，会采集一些数据用于最初的训练\n然后在接下来的训练中，机器人会一步一步 take control, 这时人类只需要做一个大致的动作就可以了。\ne.g.\n以“拿起杯子并放到指定位置”（Pick-and-Place）任务为例：\n阶段一：接近杯子 人类操作：你只需要做一个简单的“向前移动”的手势。 智能体接管：智能体理解你的意图是“去拿杯子”，于是它会自主地、平滑地控制机械手移动到杯子正上方，并摆好最佳的抓取姿势。 关键节点 1 到达：机械手已经就位，悬停在杯子上方。第一个子任务“接近杯子”已完成。此时，智能体停下来，因为它不知道你接下来是想抓取，还是想调整位置，或是想取消任务。它在等待你的下一个指令。\n阶段二：抓取杯子 人类操作：你做一个“抓握”的手势。 智能体接管：智能体接收到“抓取”指令，于是它会自主执行精确的抓取动作，以最稳定的方式合拢机械手，握紧杯子。 关键节点 2 到达：杯子已经被成功拿起。第二个子任务“抓取杯子”已完成。现在，智能体又停下来了。它知道手里拿着杯子，但它不知道你想把杯子放到哪里去。\n阶段三：移动到目标位置并释放 人类操作：你做一个指向目标位置的“移动”手势。 智能体接管：智能体理解意图，自主地将拿着杯子的手移动到目标位置上方，然后等待你最后的指令。 人类操作：你做一个“松开”的手势。 智能体接管：智能体平稳地释放杯子。任务完成。\n概念理解\nauto regressive Auto regressive 是一种生成方式。可以从前一个数生成下一个数。 更准确地说，$X_{t_i} = a_1X{t_1} + a_2X{t_2} + \\dots + a_{t_{i-1}}X{t_{i-1}}$.\nteacher forcing Teacher forcing 是指在训练的过程中，把真实信息放入训练\nPi 0\nflow matching\n连续的动作和离散的动作有什么区别\nGemini diffusion\n已加入 waitlist 正在测试 LLaDA 开源 Diffusion model. 目前该模型仍然无法加入 Chain of Thought 问题是：没有 Chain of Thought 的模型显著没有加入 Chain of Thought 的模型强 但是现在有一个叫做 Diffusion of Thought 的方法可以加入类似的东西\n",
  "wordCount" : "361",
  "inLanguage": "en",
  "datePublished": "2025-06-09T11:36:45+08:00",
  "dateModified": "2025-06-09T11:36:45+08:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://tzj2006.github.io/bugjournal/2025-06-09/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "TzJ's Net",
    "logo": {
      "@type": "ImageObject",
      "url": "https://tzj2006.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://tzj2006.github.io/" accesskey="h" title="TzJ&#39;s Net (Alt + H)">TzJ&#39;s Net</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://tzj2006.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://tzj2006.github.io/bugjournal/" title="bugJournal">
                    <span>bugJournal</span>
                </a>
            </li>
            <li>
                <a href="https://tzj2006.github.io/leetcode/" title="leetcode">
                    <span>leetcode</span>
                </a>
            </li>
            <li>
                <a href="https://tzj2006.github.io/posts/" title="posts &amp; notes">
                    <span>posts &amp; notes</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://tzj2006.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://tzj2006.github.io/bugjournal/">BugJournals</a></div>
    <h1 class="post-title entry-hint-parent">
      Bug Journal 2025-06-09
    </h1>
    <div class="post-meta"><span title='2025-06-09 11:36:45 +0800 CST'>June 9, 2025</span>&nbsp;·&nbsp;2 min


      
      <div class="meta-item">
        <span id="busuanzi_container_page_pv">
           &nbsp; People Read: <span id="busuanzi_value_page_pv"></span>
        </span>
     </div>

    </div>
  </header> 
  <div class="post-content"><h2 id="robo-dm-data-management-for-large-robot-datasets">Robo-DM: Data Management For Large Robot Datasets<a hidden class="anchor" aria-hidden="true" href="#robo-dm-data-management-for-large-robot-datasets">#</a></h2>
<p>ICRA 2025 BestPaper on Robot Learning</p>
<p>from UCB &amp; Google Deepmind</p>
<p><strong>做数据库的</strong></p>
<ol>
<li>以前的数据都没压缩过，太大了; 存储，传输成本也高</li>
<li>这样的话加载也会很慢</li>
</ol>
<p><img alt="1749461291726" loading="lazy" src="https://tzj2006.github.io/images/2025-06-09/1749461291726.png"></p>
<p>这是新的数据库格式，在兼容当前格式的情况下尽量做到了最小</p>
<p>他存储成了统一的数据格式；可以通过内存访问；可以顺序/随机访问；有模块化设计</p>
<p><img alt="1749461487133" loading="lazy" src="https://tzj2006.github.io/images/2025-06-09/1749461487133.png"></p>
<p>最后把信息都通过 EBML file 存储</p>
<p>为什么选择 EBML 呢?</p>
<p>因为：</p>
<ol>
<li>支持嵌套结构</li>
<li>是自包含的，更方便复用</li>
<li>支持流处理，不需要一次性全部导入到内存中</li>
<li>支持自动时间同步</li>
</ol>
<p>对于视频，主要选择了.H264 来压缩，显著降低了文件大小</p>
<p><img alt="1749461874888" loading="lazy" src="https://tzj2006.github.io/images/2025-06-09/1749461874888.png"></p>
<p><img alt="1749461827040" loading="lazy" src="https://tzj2006.github.io/images/2025-06-09/1749461827040.png"></p>
<p>最后这个数据集又小又快</p>
<p><img alt="1749461984813" loading="lazy" src="https://tzj2006.github.io/images/2025-06-09/1749461984813.png"></p>
<hr>
<h2 id="achieving-human-level-competitive-robot-table-tennis-a-comprehensive-overview">Achieving Human Level Competitive Robot Table Tennis: A Comprehensive Overview<a hidden class="anchor" aria-hidden="true" href="#achieving-human-level-competitive-robot-table-tennis-a-comprehensive-overview">#</a></h2>
<p>ICRA 2025 Best Paper on Robot Learning Finalist</p>
<p>from Google Deepmind</p>
<p><strong>机器人打乒乓球</strong></p>
<p>打乒乓球要又快又准。所以是理想的机器人测试器</p>
<p>对于这个机器人，用上了 模仿学习 + 强化学习 + 分层控制 + Continue Learning</p>
<p><img alt="1749462417817" loading="lazy" src="https://tzj2006.github.io/images/2025-06-09/1749462417817.png"></p>
<p>首先用模仿学习做 base, 然后强化学习训练</p>
<p>分层控制则是类似 MOE 的思路，每一个子网络都“学一种打球技术”</p>
<p>然后让主网络来“选择一种打球技术”。</p>
<p>控制频率：50HZ.</p>
<p>并且主网络还会在 Validation 的时候 Continue Learning</p>
<p>比喻：当机器人发现正手比反手好得分，那机器人就会偏向于打更多正手</p>
<p>$H(s, a) = H_{offline}(s, a) + \alpha * [R(s, a) - R_{expected}(s, a)]$</p>
<p>在这里，$H(s,a)$ 是现在的偏好
$H_{offline}(s,a)$ 是训练时的偏好
$R(s,a)$ 是当前环境的奖励
$R_{expected}$ 是预期获得的奖励</p>
<p>结果：</p>
<p><img alt="1749463060491" loading="lazy" src="https://tzj2006.github.io/images/2025-06-09/1749463060491.png"></p>
<p>此处，B 指 Beginner, I 指 Intermediate, A 指 Expert</p>
<p>训练难度：</p>
<p>2.4 Billion steps on 6k Parallel Simulators 训练出了正反手</p>
<p>每一个操作需要训练 300 - 1200 Million Steps.</p>
<p>但是推理难度很低，只需要一个 CPU 的 3ms CPU time 即可完成</p>
<p>最终能实现 50Hz 的推理速度</p>
<hr>
<h2 id="no-plan-but-everything-under-control-robustly-solving-sequential-tasks-with-dynamically-composed-gradient-descent">No Plan but Everything Under Control: Robustly Solving Sequential Tasks with Dynamically Composed Gradient Descent<a hidden class="anchor" aria-hidden="true" href="#no-plan-but-everything-under-control-robustly-solving-sequential-tasks-with-dynamically-composed-gradient-descent">#</a></h2>
<p>ICRA 2025 Best Paper on robot learning finalist</p>
<p>From University of Berlin</p>
<p>部分现有方法用的是 planning 来做的机器人 manipultaion task.</p>
<p>就是说比如会找到一个机器人的起点和终点，然后通过一些算法从起点移动到终点</p>
<p>这样的算法会通过一些数据来训练</p>
<p>但是人类在做这些 task 的时候并不会有一个 planning, 那如何不训练做这些 task 呢？</p>
<p>既然现在 Gradient Descent 这么强，能不能考虑直接用 Gradient Desent 来解决这个问题呢？</p>
<p>可以的：但是和传统的 Gradient Desnet 不一样的点在于：传统的 Gradient Desent 会把所有的 Gradient 全部加在一起，但是对于现在的 task, 不一定要找全局最优解，可以找当前“做哪个分解动作”最优。</p>
<p>比如：现在可以让机械臂向某个轴的某个方向移动，或者让机械臂把物品抓起来。</p>
<p>缺点：这个方法必须要对于每一个 task 都设计一个新的 Gradient 方向。</p>
<p>优点：这个方法可以避免一些不必要的移动，并且可以根据当前状态来调整他的策略。</p>
<p>实验设计：在“block world”模拟环境中和现实中推拉抽屉。</p>
<p><img alt="1749523102139" loading="lazy" src="https://tzj2006.github.io/images/2025-06-09/1749523102139.png"></p>
<p>在现实世界中会对于这个环境给予一个 干扰，看看这个模型的抗干扰能力如何。</p>
<p>比较的模型是：ICRA 2020: Online replanning in belief space for partially observable task and motion problems</p>
<hr>
<h2 id="polytouch-a-robust-multi-modal-tactile-sensor-for-contact-rich-manipulation">PolyTouch: A Robust Multi-Modal Tactile Sensor for Contact-rich Manipulation<a hidden class="anchor" aria-hidden="true" href="#polytouch-a-robust-multi-modal-tactile-sensor-for-contact-rich-manipulation">#</a></h2>
<p>ICRA 2025 Best Paper in Field and Service Robotics</p>
<p>使用了多种 Modality 来增强模型的 Manipulation 能力</p>
<p>使用了包括：视觉，听觉，触觉 &hellip; 等 modality 的能力</p>
<p>实验设计：</p>
<ol>
<li>耐用性</li>
<li>成功率</li>
</ol>
<p>首先和一个其他的商业模型做对比，然后发现耐用性更高</p>
<p>然后和自己做消融实验做对比，然后发现模态越多，效果越好</p>
<p><img alt="1749523849663" loading="lazy" src="https://tzj2006.github.io/images/2025-06-09/1749523849663.png"></p>
<hr>
<h2 id="human-agent-joint-learning-for-efficient-robot-manipulation-skill-acquisition">Human-Agent Joint Learning for Efficient Robot Manipulation Skill Acquisition<a hidden class="anchor" aria-hidden="true" href="#human-agent-joint-learning-for-efficient-robot-manipulation-skill-acquisition">#</a></h2>
<p>ICRA 2025 Best Paper on Human-Robot Interaction</p>
<p>From 上交 &amp; UIUC</p>
<p>提出了一种更高效的数据收集 &amp; 训练的方式</p>
<p><img alt="1749524046582" loading="lazy" src="https://tzj2006.github.io/images/2025-06-09/1749524046582.png"></p>
<p>核心在于 Diffusion Policy 的应用。</p>
<p>最开始的时候，会采集一些数据用于最初的训练</p>
<p>然后在接下来的训练中，机器人会一步一步 take control, 这时人类只需要做一个大致的动作就可以了。</p>
<p>e.g.</p>
<p>以“拿起杯子并放到指定位置”（Pick-and-Place）任务为例：</p>
<p>阶段一：接近杯子
人类操作：你只需要做一个简单的“向前移动”的手势。
智能体接管：智能体理解你的意图是“去拿杯子”，于是它会自主地、平滑地控制机械手移动到杯子正上方，并摆好最佳的抓取姿势。
关键节点 1 到达：机械手已经就位，悬停在杯子上方。第一个子任务“接近杯子”已完成。此时，智能体停下来，因为它不知道你接下来是想抓取，还是想调整位置，或是想取消任务。它在等待你的下一个指令。</p>
<p>阶段二：抓取杯子
人类操作：你做一个“抓握”的手势。
智能体接管：智能体接收到“抓取”指令，于是它会自主执行精确的抓取动作，以最稳定的方式合拢机械手，握紧杯子。
关键节点 2 到达：杯子已经被成功拿起。第二个子任务“抓取杯子”已完成。现在，智能体又停下来了。它知道手里拿着杯子，但它不知道你想把杯子放到哪里去。</p>
<p>阶段三：移动到目标位置并释放
人类操作：你做一个指向目标位置的“移动”手势。
智能体接管：智能体理解意图，自主地将拿着杯子的手移动到目标位置上方，然后等待你最后的指令。
人类操作：你做一个“松开”的手势。
智能体接管：智能体平稳地释放杯子。任务完成。</p>
<hr>
<p>概念理解</p>
<ol>
<li>auto regressive</li>
</ol>
<p>Auto regressive 是一种生成方式。可以从前一个数生成下一个数。
更准确地说，$X_{t_i} = a_1X{t_1} + a_2X{t_2} + \dots + a_{t_{i-1}}X{t_{i-1}}$.</p>
<ol start="2">
<li>teacher forcing</li>
</ol>
<p>Teacher forcing 是指在训练的过程中，把真实信息放入训练</p>
<ol start="4">
<li>
<p>Pi 0</p>
</li>
<li>
<p>flow matching</p>
</li>
<li>
<p>连续的动作和离散的动作有什么区别</p>
</li>
<li>
<p>Gemini diffusion</p>
</li>
</ol>
<p>已加入 waitlist
正在测试 LLaDA 开源 Diffusion model.
目前该模型仍然无法加入 Chain of Thought
问题是：没有 Chain of Thought 的模型显著没有加入 Chain of Thought 的模型强
但是现在有一个叫做 Diffusion of Thought 的方法可以加入类似的东西</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://tzj2006.github.io/">TzJ&#39;s Net</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
    <span>
        · 本站访客数：<span id="busuanzi_value_site_uv"></span>
        · 总访问量：<span id="busuanzi_value_site_pv"></span>
    </span>
    
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
