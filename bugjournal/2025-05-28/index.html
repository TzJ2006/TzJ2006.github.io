<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Bug Journal 2025-05-28 | TzJ&#39;s Net</title>
<meta name="keywords" content="Bug Journal, Robotics, Paper Reading">
<meta name="description" content="2025-05-28 论文阅读笔记">
<meta name="author" content="">
<link rel="canonical" href="https://tzj2006.github.io/bugjournal/2025-05-28/">

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
  <meta name="referrer" content="no-referrer-when-downgrade">
<link crossorigin="anonymous" href="https://tzj2006.github.io/assets/css/stylesheet.af858c2feef42adc7846f815c3e21de9982d82f8fc4f65879451b2686859975a.css" integrity="sha256-r4WML&#43;70Ktx4RvgVw&#43;Id6Zgtgvj8T2WHlFGyaGhZl1o=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://tzj2006.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://tzj2006.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://tzj2006.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://tzj2006.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://tzj2006.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://tzj2006.github.io/bugjournal/2025-05-28/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>

<script type="text/javascript" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>


<script src="https://tzj2006.github.io/js/checkbox-state.min.481208bf28be32dd7419d90065130144ba9a464a94857de0dc07fd19d3f2f6f3.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous">

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js" integrity="sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY" crossorigin="anonymous"></script>

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js" integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>


<script>
document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "$", right: "$", display: false}
        ]
    });
});
</script>
<meta property="og:url" content="https://tzj2006.github.io/bugjournal/2025-05-28/">
  <meta property="og:site_name" content="TzJ&#39;s Net">
  <meta property="og:title" content="Bug Journal 2025-05-28">
  <meta property="og:description" content="2025-05-28 论文阅读笔记">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="bugjournal">
    <meta property="article:published_time" content="2025-05-28T14:41:55+08:00">
    <meta property="article:modified_time" content="2025-05-28T14:41:55+08:00">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Bug Journal 2025-05-28">
<meta name="twitter:description" content="2025-05-28 论文阅读笔记">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "BugJournals",
      "item": "https://tzj2006.github.io/bugjournal/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Bug Journal 2025-05-28",
      "item": "https://tzj2006.github.io/bugjournal/2025-05-28/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Bug Journal 2025-05-28",
  "name": "Bug Journal 2025-05-28",
  "description": "2025-05-28 论文阅读笔记",
  "keywords": [
    "Bug Journal", "Robotics", "Paper Reading"
  ],
  "articleBody": "SKIL: Semantic Keypoint Imitation Learning for Generalizable Data-efficient Manipulation 发表时间：24 Jan 2025\n主要论点 这篇文章提出了一种新的模仿学习框架 SKIL（Semantic Keypoint Imitation Learning），通过结合视觉基础模型自动提取“语义关键点”（semantic keypoints），使得机器人在仅有少量示范的条件下，依然能完成具有泛化能力和复杂步骤的操作任务（如挂毛巾、折叠布料等）。该方法显著降低了训练所需的数据量，并且在未见过的物体与场景中也表现出优越的泛化能力。\nHow can we reduce sample complexity to enable robots to learn data-efficient and generalizable manipulation tasks?\n模型流程图 创新点 自动语义关键点提取： 借助如 DiFT 等视觉基础模型与 SAM，对参考图像中的目标区域进行聚类，自动生成语义关键点，不需要人工标注或专门训练。 语义关键点描述符（descriptor）设计： 结合相似度向量（cosine similarity）与 3D 坐标构建表示，每个关键点携带语义和空间信息。 结合 Diffusion Policy 输出动作序列： 使用 Transformer 编码器和扩散模型作为动作头，实现连续动作输出。 支持跨主体学习（Cross-embodiment）： 提出的 SKIL-H 模块允许利用人类视频（无动作标签）进行辅助训练，提高数据效率和泛化性。 Ensemble 推理策略： 在推理阶段进行关键点子集 dropout 与多次采样求中位数，从而降低视觉匹配误差带来的动作抖动。\nbb*SKIL-H: ** 可以把第三人称视角人的视频转换为辅助训练的数据集\n使用一个 frozen 的通用关键点检测器（如 SAM-Track 或 VIT tracker），输出每一帧的人体相关关键点（如手、手指等）。 画出这些关键点之间的轨迹 将人类演示中关键点的表示映射到机器人操作空间中的目标关键点 直接用 transformer 编码 解决的难点 利用视觉大模型提取对任务有语义意义的关键点，极大降低了状态空间维度； 通过高质量、稀疏但语义强的关键点建模，提升少样本学习能力； 使用 Transformer + Diffusion Policy 构建策略网络，强化连续动作输出的能力； 提供了一种利用人类演示辅助学习的方法，不依赖标注动作。 之前方法的缺点 慢：比如ACT要收集上万个数据; GenGP 用的是完整的语意场，有太多信息了 只预测关键帧，而不是连续的动作 (注：我认为这里说不定关键帧可能好一点) 预测连续动作的模型没有 generalizability 还需要解决的难点 关键点提取质量依赖于视觉基础模型能力： 如在 “Bulb Assembly” 等精度要求极高的任务中，DiFT 模型提取的关键点不够精确，导致失败。 忽略环境障碍与场景信息： 当前关键点只从目标对象上提取，无法感知障碍物等环境元素，可能导致安全问题。 固定视角与姿态： 当前工作主要依赖固定的第三视角 RGBD 摄像头，泛化到第一视角或动态视角仍有挑战。 动作表示维度有限： 尚未充分拓展到高自由度控制（如仿人手）、复杂轨迹规划等更广泛的应用场景。 泛化问题：这个模型并不是 zero-shot,而是每个 task 都单独 train 了一个 model\nTake away semantic keypoints: 语义关键点 指的是一个物体和操作相关的哪一个部分。比如杯子上的把手\ncosine similarity 可以获得不同关键点之间的相似度，相当于某种位置信息；之后可以把真正的位置信息也嵌入进去。\nDiffusion Policy: 这种方法使得 multi-model 变得可行\noff-the-shelf tracking models: 约等于已经开源的动作跟踪实现\n数据集 Meta World\nDATA SCALING LAWS IN IMITATION LEARNING FOR ROBOTIC MANIPULATION 发表时间：24 Oct 2024 修改于：12 Feb 2025\n主要论点 这篇文章研究了模仿学习中的数据规模定律(data scaling laws) 在机器人操作任务中的适用性，核心问题是：\n在不同环境和不同物体下增加演示数据量，是否能提升策略的泛化能力，进而使单任务策略在新环境和新物体上零样本部署成为可能？\n作者通过在真实世界收集超 4 万条人类演示、1.5 万次机器人 rollout，基于 Diffusion Policy 训练策略，在多个任务上发现：\n泛化性能随着训练环境/物体/环境-物体组合数量近似呈幂律增长，即：$y = \\alpha x ^ \\beta$, 其中，y 是用 normalized score 来衡量的泛化性能，x 是样本的多样性。 同一个物体或环境上多收集数据的效果远远不如增加多样性； 实证证明仅需 32 个不同环境-物体组合、每个 50 个演示，就能训练出成功率超 90% 的策略。 模型流程图 创新点 首次系统性提出并验证模仿学习中机器人操控的“scaling law” 测试了 环境泛化 + 物体泛化； 提出了一个高效数据采集策略：以环境和物体的多样性优先，不盲目增加演示数量； 在多项任务上（Pour Water、Mouse Arrangement、Fold Towels、Unplug Charger）进行大规模真实机器人验证； 对视觉模型和动作模型的扩展进行了 ablation study，验证视觉编码器更关键。 解决的难点 数据量大 还需要解决的难点 只验证了四个任务，任务种类仍有限，无法保证适用于所有任务 只使用了 Diffusion Policy，未评估不同学习算法对 scaling law 的依赖性差异 未来还将验证 Reinforcement Learning 的 scaling law. Take away 为了获得更好的泛化能力，采集更多不同的环境 ($# \u003e 16$) \u003e 在同一个环境中堆砌多个物体样本\nLearning to Plan Before Answering: Self-Teaching LLMs to Learn Abstract Plans for Problem Solving 发表时间：22 Jan 2025\n主要论点 这篇文章提出了一种新颖的自我训练方法 LEPA（Learning to Plan before Answering），训练 LLM 在生成具体解答前，先生成高层次的抽象“计划”。这些“计划”是通用的元知识（meta-knowledge），可以指导模型更有效地推理和解题。\n具体流程如下： 1.\t模型先生成anticipatory plan（预测性计划）：对问题的大致解题策略。 2.\t再基于这个计划生成具体解答。 3.\t如果解答错误，模型会进行 自我反思（self-reflection），调整 plan 并重新解题，直到成功或达到最大尝试次数。 4.\t最终用 plan + solution 对模型进行监督微调（Supervised Fine-Tuning）。\n模型流程图 创新点 引入 anticipatory plan：首次在自我训练中加入计划作为元知识，帮助 LLM 更清晰地组织解题路径。 计划 + 解答联合训练：不仅学习答案，还学习如何规划解题路径，提高泛化性。 自我反思机制：错误时能分析原因并优化 plan，不再依赖外部标签。 信息隔离设计：计划不能包含具体答案细节，避免 LLM 投机取巧。 可与 RL 兼容扩展：初步展示了 LEPA 与 RL（REINFORCE）结合后的性能提升。 之前方法的缺点 没有引导模型形成通用的解题策略 → 泛化能力差； 错误的修改方式（如修改最终答案而非解题路径）容易产生假阳性答案； 缺少系统性规划与反思机制 。 解决的难点 自我训练生成的数据质量不足、泛化能力差，尤其是在复杂的数学和推理任务上表现不佳。\n之前的方法无法抽象出问题：比如，在做物理题时先抽象出公式，然后再代数运算。\n还需要解决的难点 计划与答案不一致问题：计划可能无法完全约束模型生成的推理步骤； 复杂度与推理选择权平衡：对于简单问题，可能不需要计划，LEPA 可能浪费计算； 计划的质量仍依赖 LLM 自身能力 ，弱模型难以产生有用计划； RL 优化仍是初步探索，与更强 RL 算法结合仍是未来方向； Take away Fine-Tuning Hard-to-Simulate Objectives for Quadruped Locomotion: A Case Study on Total Power Saving 主要论点 本文提出一种针对四足机器人“难以在仿真中准确建模”的目标（如总电池功耗）进行优化的数据驱动微调方法。核心思想是：\n先用预训练策略在现实中采集数据； 训练一个“测量模型”来预测那些仿真环境中缺失或误差较大的目标（如总电流）； 将这个模型集成到仿真中，作为奖励函数优化新策略； 通过仿真+现实评估的迭代更新，逐步提升策略在真实世界中的表现。 他们以“降低四足机器人总功耗”为目标，在 Unitree Go1 上进行实证研究，结果显示电池功耗减少了 24-28%。\n模型流程图 创新点 数据驱动的测量模型作为奖励代理：直接从现实数据学习一个预测真实目标的模型（如总电流），替代传统的机械功或热功率等代理指标。 目标不可建模时的微调框架：将测量模型集成进仿真中，使得原本难以仿真的目标也可以用于训练优化。 层级策略选择机制：候选策略先在仿真中初选，再在现实中精评，保留最优用于下次迭代。 迭代式收集数据 + 微调：不断积累现实数据、优化测量模型、提升策略性能，达到持续优化的效果。 解决的难点 传统 sim-to-real 方法依赖物理仿真器（如 MuJoCo），但这些仿真器通常无法准确建模：\n电池电流/电压（尤其是 PMSM 电机复杂控制） 步态噪声 电机过热等非刚体物理特性 之前方法的缺点 使用代理目标 (如机械功) 不够准确，甚至误导优化过程； 现实直接训练 RL 效率低，只适用于简单任务； 以往方法不支持针对新目标进行微调（例如预训练时没有考虑节能目标，无法直接迁移）。 还需要解决的难点 需大量真实数据才能收敛（约 38 万个样本）； 测量模型存在分布偏移（Out-of-Distribution）问题； 实验仅在 Unitree Go1 和平地环境下进行，缺乏跨机器人、复杂地形验证； 没有测试对其他 hard-to-simulate 目标（如声音、热量）的迁移适应性。 Take away Revisit when doing a robot dog related task.\n关注文章的 Motivation\n关注文章的 Motivation 是怎么和方法联系起来的\n关注文章是如何卖出去的\n",
  "wordCount" : "396",
  "inLanguage": "en",
  "datePublished": "2025-05-28T14:41:55+08:00",
  "dateModified": "2025-05-28T14:41:55+08:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://tzj2006.github.io/bugjournal/2025-05-28/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "TzJ's Net",
    "logo": {
      "@type": "ImageObject",
      "url": "https://tzj2006.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://tzj2006.github.io/" accesskey="h" title="TzJ&#39;s Net (Alt + H)">TzJ&#39;s Net</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://tzj2006.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://tzj2006.github.io/bugjournal/" title="bugJournal">
                    <span>bugJournal</span>
                </a>
            </li>
            <li>
                <a href="https://tzj2006.github.io/leetcode/" title="leetcode">
                    <span>leetcode</span>
                </a>
            </li>
            <li>
                <a href="https://tzj2006.github.io/posts/" title="posts &amp; notes">
                    <span>posts &amp; notes</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://tzj2006.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://tzj2006.github.io/bugjournal/">BugJournals</a></div>
    <h1 class="post-title entry-hint-parent">
      Bug Journal 2025-05-28
    </h1>
    <div class="post-meta"><span title='2025-05-28 14:41:55 +0800 +0800'>May 28, 2025</span>&nbsp;·&nbsp;2 min


      
      <div class="meta-item">
        <span id="busuanzi_container_page_pv">
           &nbsp; People Read: <span id="busuanzi_value_page_pv"></span>
        </span>
     </div>

    </div>
  </header> 
  <div class="post-content"><h3 id="skil-semantic-keypoint-imitation-learning-for-generalizable-data-efficient-manipulation">SKIL: Semantic Keypoint Imitation Learning for Generalizable Data-efficient Manipulation<a hidden class="anchor" aria-hidden="true" href="#skil-semantic-keypoint-imitation-learning-for-generalizable-data-efficient-manipulation">#</a></h3>
<p><a href="https://arxiv.org/abs/2501.14400">发表时间：24 Jan 2025</a></p>
<h4 id="主要论点">主要论点<a hidden class="anchor" aria-hidden="true" href="#主要论点">#</a></h4>
<p>这篇文章提出了一种新的模仿学习框架 <strong>SKIL（Semantic Keypoint Imitation Learning）</strong>，通过结合视觉基础模型自动提取“语义关键点”（semantic keypoints），使得机器人在仅有少量示范的条件下，依然能完成具有泛化能力和复杂步骤的操作任务（如挂毛巾、折叠布料等）。该方法显著降低了训练所需的数据量，并且在未见过的物体与场景中也表现出优越的泛化能力。</p>
<p>How can we reduce sample complexity to enable robots to learn data-efficient and generalizable manipulation tasks?</p>
<h4 id="模型流程图">模型流程图<a hidden class="anchor" aria-hidden="true" href="#模型流程图">#</a></h4>
<p><img alt="1748418079414" loading="lazy" src="https://tzj2006.github.io/images/2025-05-28/1748418079414.png"></p>
<h4 id="创新点">创新点<a hidden class="anchor" aria-hidden="true" href="#创新点">#</a></h4>
<p><strong>自动语义关键点提取：</strong> 借助如 DiFT 等视觉基础模型与 SAM，对参考图像中的目标区域进行聚类，自动生成语义关键点，不需要人工标注或专门训练。
<strong>语义关键点描述符（descriptor）设计：</strong> 结合相似度向量（cosine similarity）与 3D 坐标构建表示，每个关键点携带语义和空间信息。
<strong>结合 Diffusion Policy 输出动作序列：</strong> 使用 Transformer 编码器和扩散模型作为动作头，实现连续动作输出。
<strong>支持跨主体学习（Cross-embodiment）：</strong> 提出的 SKIL-H 模块允许利用人类视频（无动作标签）进行辅助训练，提高数据效率和泛化性。
<strong>Ensemble 推理策略：</strong> 在推理阶段进行关键点子集 dropout 与多次采样求中位数，从而降低视觉匹配误差带来的动作抖动。</p>
<p>bb*SKIL-H: ** 可以把第三人称视角人的视频转换为辅助训练的数据集</p>
<ol>
<li>使用一个 frozen 的通用关键点检测器（如 SAM-Track 或 VIT tracker），输出每一帧的人体相关关键点（如手、手指等）。</li>
<li>画出这些关键点之间的轨迹</li>
<li>将人类演示中关键点的表示映射到机器人操作空间中的目标关键点</li>
<li>直接用 transformer 编码</li>
</ol>
<h4 id="解决的难点">解决的难点<a hidden class="anchor" aria-hidden="true" href="#解决的难点">#</a></h4>
<ul>
<li>利用视觉大模型提取对任务有语义意义的关键点，极大降低了状态空间维度；</li>
<li>通过高质量、稀疏但语义强的关键点建模，提升少样本学习能力；</li>
<li>使用 Transformer + Diffusion Policy 构建策略网络，强化连续动作输出的能力；</li>
<li>提供了一种利用人类演示辅助学习的方法，不依赖标注动作。</li>
</ul>
<h4 id="之前方法的缺点">之前方法的缺点<a hidden class="anchor" aria-hidden="true" href="#之前方法的缺点">#</a></h4>
<ol>
<li>慢：比如ACT要收集上万个数据; GenGP 用的是完整的语意场，有太多信息了</li>
<li>只预测关键帧，而不是连续的动作 (注：我认为这里说不定关键帧可能好一点)</li>
<li>预测连续动作的模型没有 generalizability</li>
</ol>
<h4 id="还需要解决的难点">还需要解决的难点<a hidden class="anchor" aria-hidden="true" href="#还需要解决的难点">#</a></h4>
<p><strong>关键点提取质量依赖于视觉基础模型能力：</strong> 如在 “Bulb Assembly” 等精度要求极高的任务中，DiFT 模型提取的关键点不够精确，导致失败。
<strong>忽略环境障碍与场景信息：</strong> 当前关键点只从目标对象上提取，无法感知障碍物等环境元素，可能导致安全问题。
<strong>固定视角与姿态：</strong> 当前工作主要依赖固定的第三视角 RGBD 摄像头，泛化到第一视角或动态视角仍有挑战。
<strong>动作表示维度有限：</strong> 尚未充分拓展到高自由度控制（如仿人手）、复杂轨迹规划等更广泛的应用场景。
<strong>泛化问题：这个模型并不是 zero-shot,而是每个 task 都单独 train 了一个 model</strong></p>
<h4 id="take-away">Take away<a hidden class="anchor" aria-hidden="true" href="#take-away">#</a></h4>
<p>semantic keypoints: 语义关键点 指的是一个物体和操作相关的哪一个部分。比如杯子上的把手</p>
<p>cosine similarity 可以获得不同关键点之间的相似度，相当于某种位置信息；之后可以把真正的位置信息也嵌入进去。</p>
<p>Diffusion Policy: 这种方法使得 multi-model 变得可行</p>
<p>off-the-shelf tracking models: 约等于已经开源的动作跟踪实现</p>
<p>数据集 <a href="https://arxiv.org/pdf/1910.10897">Meta World</a></p>
<h3 id="data-scaling-laws-in-imitation-learning-for-robotic-manipulation">DATA SCALING LAWS IN IMITATION LEARNING FOR ROBOTIC MANIPULATION<a hidden class="anchor" aria-hidden="true" href="#data-scaling-laws-in-imitation-learning-for-robotic-manipulation">#</a></h3>
<p><a href="https://arxiv.org/abs/2410.18647">发表时间：24 Oct 2024</a>
修改于：12 Feb 2025</p>
<h4 id="主要论点-1">主要论点<a hidden class="anchor" aria-hidden="true" href="#主要论点-1">#</a></h4>
<p>这篇文章研究了<strong>模仿学习中的数据规模定律(data scaling laws)</strong> 在机器人操作任务中的适用性，核心问题是：</p>
<p><strong>在不同环境和不同物体下增加演示数据量，是否能提升策略的泛化能力，进而使单任务策略在新环境和新物体上零样本部署成为可能？</strong></p>
<p>作者通过在真实世界收集超 4 万条人类演示、1.5 万次机器人 rollout，基于 Diffusion Policy 训练策略，在多个任务上发现：</p>
<ul>
<li>泛化性能随着训练环境/物体/环境-物体组合数量近似呈<strong>幂律增长</strong>，即：$y = \alpha x ^ \beta$, 其中，y 是用 normalized score 来衡量的泛化性能，x 是样本的多样性。</li>
<li>同一个物体或环境上多收集数据的效果远远不如增加多样性；</li>
<li>实证证明仅需 32 个不同环境-物体组合、每个 50 个演示，就能训练出成功率超 90% 的策略。</li>
</ul>
<h4 id="模型流程图-1">模型流程图<a hidden class="anchor" aria-hidden="true" href="#模型流程图-1">#</a></h4>
<h4 id="创新点-1">创新点<a hidden class="anchor" aria-hidden="true" href="#创新点-1">#</a></h4>
<ol>
<li><strong>首次系统性提出并验证模仿学习中机器人操控的“scaling law”</strong></li>
<li>测试了 环境泛化 + 物体泛化；</li>
<li>提出了一个<strong>高效数据采集策略</strong>：以环境和物体的多样性优先，不盲目增加演示数量；</li>
<li>在多项任务上（Pour Water、Mouse Arrangement、Fold Towels、Unplug Charger）进行大规模真实机器人验证；</li>
<li>对视觉模型和动作模型的扩展进行了 ablation study，验证视觉编码器更关键。</li>
</ol>
<h4 id="解决的难点-1">解决的难点<a hidden class="anchor" aria-hidden="true" href="#解决的难点-1">#</a></h4>
<ol>
<li>数据量大</li>
</ol>
<h4 id="还需要解决的难点-1">还需要解决的难点<a hidden class="anchor" aria-hidden="true" href="#还需要解决的难点-1">#</a></h4>
<ol>
<li>只验证了四个任务，任务种类仍有限，无法保证适用于所有任务</li>
<li>只使用了 Diffusion Policy，未评估不同学习算法对 scaling law 的依赖性差异</li>
<li>未来还将验证 Reinforcement Learning 的 scaling law.</li>
</ol>
<h4 id="take-away-1">Take away<a hidden class="anchor" aria-hidden="true" href="#take-away-1">#</a></h4>
<p>为了获得更好的泛化能力，采集更多不同的环境 ($# &gt; 16$) &gt; 在同一个环境中堆砌多个物体样本</p>
<h3 id="learning-to-plan-before-answering-self-teaching-llms-to-learn-abstract-plans-for-problem-solving">Learning to Plan Before Answering: Self-Teaching LLMs to Learn Abstract Plans for Problem Solving<a hidden class="anchor" aria-hidden="true" href="#learning-to-plan-before-answering-self-teaching-llms-to-learn-abstract-plans-for-problem-solving">#</a></h3>
<p><a href="https://openreview.net/pdf?id=KmmNb7631I">发表时间：22 Jan 2025</a></p>
<h4 id="主要论点-2">主要论点<a hidden class="anchor" aria-hidden="true" href="#主要论点-2">#</a></h4>
<p>这篇文章提出了一种新颖的自我训练方法 LEPA（Learning to Plan before Answering），训练 LLM 在生成具体解答前，先生成高层次的抽象“计划”。这些“计划”是通用的元知识（meta-knowledge），可以指导模型更有效地推理和解题。</p>
<p>具体流程如下：
1.	模型先生成anticipatory plan（预测性计划）：对问题的大致解题策略。
2.	再基于这个计划生成具体解答。
3.	如果解答错误，模型会进行 自我反思（self-reflection），调整 plan 并重新解题，直到成功或达到最大尝试次数。
4.	最终用 plan + solution 对模型进行监督微调（Supervised Fine-Tuning）。</p>
<h4 id="模型流程图-2">模型流程图<a hidden class="anchor" aria-hidden="true" href="#模型流程图-2">#</a></h4>
<h4 id="创新点-2">创新点<a hidden class="anchor" aria-hidden="true" href="#创新点-2">#</a></h4>
<ol>
<li><strong>引入 anticipatory plan</strong>：首次在自我训练中加入计划作为元知识，帮助 LLM 更清晰地组织解题路径。</li>
<li><strong>计划 + 解答联合训练</strong>：不仅学习答案，还学习如何规划解题路径，提高泛化性。</li>
<li><strong>自我反思机制</strong>：错误时能分析原因并优化 plan，不再依赖外部标签。</li>
<li><strong>信息隔离设计</strong>：计划不能包含具体答案细节，避免 LLM 投机取巧。</li>
<li><strong>可与 RL 兼容扩展</strong>：初步展示了 LEPA 与 RL（REINFORCE）结合后的性能提升。</li>
</ol>
<h4 id="之前方法的缺点-1">之前方法的缺点<a hidden class="anchor" aria-hidden="true" href="#之前方法的缺点-1">#</a></h4>
<ul>
<li>没有引导模型形成通用的解题策略 → 泛化能力差；</li>
<li>错误的修改方式（如修改最终答案而非解题路径）容易产生假阳性答案；</li>
<li><strong>缺少系统性规划与反思机制</strong> <strong>。</strong></li>
</ul>
<h4 id="解决的难点-2">解决的难点<a hidden class="anchor" aria-hidden="true" href="#解决的难点-2">#</a></h4>
<p>自我训练生成的数据质量不足、泛化能力差，尤其是在复杂的数学和推理任务上表现不佳。</p>
<p>之前的方法无法抽象出问题：比如，在做物理题时先抽象出公式，然后再代数运算。</p>
<h4 id="还需要解决的难点-2">还需要解决的难点<a hidden class="anchor" aria-hidden="true" href="#还需要解决的难点-2">#</a></h4>
<ol>
<li><strong>计划与答案不一致问题</strong>：计划可能无法完全约束模型生成的推理步骤；</li>
<li><strong>复杂度与推理选择权平衡</strong>：对于简单问题，可能不需要计划，LEPA 可能浪费计算；</li>
<li><strong>计划的质量仍依赖 LLM 自身能力</strong> <strong>，弱模型难以产生有用计划；</strong></li>
<li><strong>RL 优化仍是初步探索</strong>，与更强 RL 算法结合仍是未来方向；</li>
</ol>
<h4 id="take-away-2">Take away<a hidden class="anchor" aria-hidden="true" href="#take-away-2">#</a></h4>
<p><img alt="1748424315398" loading="lazy" src="https://tzj2006.github.io/images/2025-05-28/1748424315398.png"></p>
<hr>
<h3 id="fine-tuning-hard-to-simulate-objectives-for-quadruped-locomotion-a-case-study-on-total-power-saving">Fine-Tuning Hard-to-Simulate Objectives for Quadruped Locomotion: A Case Study on Total Power Saving<a hidden class="anchor" aria-hidden="true" href="#fine-tuning-hard-to-simulate-objectives-for-quadruped-locomotion-a-case-study-on-total-power-saving">#</a></h3>
<h4 id="主要论点-3">主要论点<a hidden class="anchor" aria-hidden="true" href="#主要论点-3">#</a></h4>
<p>本文提出一种针对四足机器人“难以在仿真中准确建模”的目标（如总电池功耗）进行优化的<strong>数据驱动微调方法</strong>。核心思想是：</p>
<ul>
<li>先用预训练策略在现实中采集数据；</li>
<li>训练一个“测量模型”来预测那些仿真环境中缺失或误差较大的目标（如总电流）；</li>
<li>将这个模型集成到仿真中，作为奖励函数优化新策略；</li>
<li>通过仿真+现实评估的迭代更新，逐步提升策略在真实世界中的表现。</li>
</ul>
<p>他们以“降低四足机器人总功耗”为目标，在 Unitree Go1 上进行实证研究，结果显示电池功耗减少了 24-28%。</p>
<h4 id="模型流程图-3">模型流程图<a hidden class="anchor" aria-hidden="true" href="#模型流程图-3">#</a></h4>
<h4 id="创新点-3">创新点<a hidden class="anchor" aria-hidden="true" href="#创新点-3">#</a></h4>
<ul>
<li><strong>数据驱动的测量模型作为奖励代理</strong>：直接从现实数据学习一个预测真实目标的模型（如总电流），替代传统的机械功或热功率等代理指标。</li>
<li><strong>目标不可建模时的微调框架</strong>：将测量模型集成进仿真中，使得原本难以仿真的目标也可以用于训练优化。</li>
<li><strong>层级策略选择机制</strong>：候选策略先在仿真中初选，再在现实中精评，保留最优用于下次迭代。</li>
<li><strong>迭代式收集数据 + 微调</strong>：不断积累现实数据、优化测量模型、提升策略性能，达到持续优化的效果。</li>
</ul>
<h4 id="解决的难点-3">解决的难点<a hidden class="anchor" aria-hidden="true" href="#解决的难点-3">#</a></h4>
<p>传统 sim-to-real 方法依赖物理仿真器（如 MuJoCo），但这些仿真器通常无法准确建模：</p>
<ul>
<li>电池电流/电压（尤其是 PMSM 电机复杂控制）</li>
<li>步态噪声</li>
<li>电机过热等非刚体物理特性</li>
</ul>
<h4 id="之前方法的缺点-2">之前方法的缺点<a hidden class="anchor" aria-hidden="true" href="#之前方法的缺点-2">#</a></h4>
<ul>
<li><strong>使用代理目标 (如机械功)</strong> 不够准确，甚至误导优化过程；</li>
<li><strong>现实直接训练 RL</strong> 效率低，只适用于简单任务；</li>
<li><strong>以往方法不支持针对新目标进行微调</strong>（例如预训练时没有考虑节能目标，无法直接迁移）。</li>
</ul>
<h4 id="还需要解决的难点-3">还需要解决的难点<a hidden class="anchor" aria-hidden="true" href="#还需要解决的难点-3">#</a></h4>
<ul>
<li>需大量真实数据才能收敛（约 38 万个样本）；</li>
<li>测量模型存在分布偏移（Out-of-Distribution）问题；</li>
<li>实验仅在 Unitree Go1 和平地环境下进行，<strong>缺乏跨机器人、复杂地形验证</strong>；</li>
<li>没有测试对其他 hard-to-simulate 目标（如声音、热量）的迁移适应性。</li>
</ul>
<h4 id="take-away-3">Take away<a hidden class="anchor" aria-hidden="true" href="#take-away-3">#</a></h4>
<p><strong>Revisit when doing a robot dog related task.</strong></p>
<p>关注文章的 Motivation</p>
<p>关注文章的 Motivation 是怎么和方法联系起来的</p>
<p>关注文章是如何卖出去的</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://tzj2006.github.io/">TzJ&#39;s Net</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
    <span>
        · 本站访客数：<span id="busuanzi_value_site_uv"></span>
        · 总访问量：<span id="busuanzi_value_site_pv"></span>
    </span>
    
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
