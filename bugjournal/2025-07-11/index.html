<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Bug Journal 2025-07-11 | TzJ&#39;s Net</title>
<meta name="keywords" content="Bug Journal, LoRA">
<meta name="description" content="LoRA tutorial">
<meta name="author" content="">
<link rel="canonical" href="https://tzj2006.github.io/bugjournal/2025-07-11/">

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
  <meta name="referrer" content="no-referrer-when-downgrade">
<link crossorigin="anonymous" href="https://tzj2006.github.io/assets/css/stylesheet.af858c2feef42adc7846f815c3e21de9982d82f8fc4f65879451b2686859975a.css" integrity="sha256-r4WML&#43;70Ktx4RvgVw&#43;Id6Zgtgvj8T2WHlFGyaGhZl1o=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://tzj2006.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://tzj2006.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://tzj2006.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://tzj2006.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://tzj2006.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://tzj2006.github.io/bugjournal/2025-07-11/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>

<script type="text/javascript" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>


<script src="https://tzj2006.github.io/js/checkbox-state.min.481208bf28be32dd7419d90065130144ba9a464a94857de0dc07fd19d3f2f6f3.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous">

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js" integrity="sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY" crossorigin="anonymous"></script>

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js" integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>


<script>
document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "$", right: "$", display: false}
        ]
    });
});
</script>
<meta property="og:url" content="https://tzj2006.github.io/bugjournal/2025-07-11/">
  <meta property="og:site_name" content="TzJ&#39;s Net">
  <meta property="og:title" content="Bug Journal 2025-07-11">
  <meta property="og:description" content="LoRA tutorial">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="bugjournal">
    <meta property="article:published_time" content="2025-07-11T11:33:41+08:00">
    <meta property="article:modified_time" content="2025-07-11T11:33:41+08:00">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Bug Journal 2025-07-11">
<meta name="twitter:description" content="LoRA tutorial">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "BugJournals",
      "item": "https://tzj2006.github.io/bugjournal/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Bug Journal 2025-07-11",
      "item": "https://tzj2006.github.io/bugjournal/2025-07-11/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Bug Journal 2025-07-11",
  "name": "Bug Journal 2025-07-11",
  "description": "LoRA tutorial",
  "keywords": [
    "Bug Journal", "LoRA"
  ],
  "articleBody": "LoRA finetuning 之前一直听说 LoRA 的大名，今天来看看 LoRA 到底在做什么\n正好我看到了 huggingface 上有 LoRA tutorial 所以就过来研究了一下🧐\n注：代码顺序与 tutorial中略有出入\n省流：想看 LoRA specific 的同学请直接从[这里开始看](#Step 5: 训练前准备)\nStep1: 导入需要用到的 package import transformers import accelerate import torch import peft print(f\"transformers version: {transformers.__version__}\") print(f\"accelerate version: {accelerate.__version__}\") print(f\"torch version: {torch.__version__}\") print(f\"peft version: {peft.__version__}\") 需要导入的 package 大概就这么几个，首先是 transformers, accelerate, torch 和 peft\n今天这个 LoRA 主要就是用的 peft package.\n至于 accelerate, 就是用来加速 peft 的\nStep2: 数据集加载 # 接下来加载数据集 # 这里我们使用的是 Hugging Face 的 datasets 库来加载 Food101 数据集 from datasets import load_dataset # dataset = load_dataset(\"food101\", split=\"train[:5000]\") # 只加载前5000个样本以加快速度 dataset = load_dataset(\"food101\", split=\"train+validation\") # 加载整个数据集 from datasets import Image as DatasetsImage dataset = dataset.cast_column(\"image\", DatasetsImage(decode=False)) # 然后把标签拿出来 # 这里 huggingface 要求一个 labeltoid \u0026 idtolabel # 所以这里要弄两个 map 互相 map labels = dataset.features[\"label\"].names label2id, id2label = dict(), dict() for i, label in enumerate(labels): label2id[label] = i id2label[i] = label 这里demo中用的是Food101数据集 (老演员了[doge]),\n但是这个作为 classification 的数据集其实不太好（因为食物的种类非常非常多\n但是作为LoRA刚刚好，因为LoRA就是专门针对这个事情的\n加载这个部分倒是没什么好说的\n最后这个 .cast_column 是后来发现这个数据集存的是二进制文件，所以不能 decode (by ChatGPT)\nStep3: 加载预训练模型 这个很重要！！, 不要到时候跑起来了发现没有导入预训练模型\n注：如果没有加载预训练模型，不会有任何 Warning or Error，什么都可以正常跑，但是跑到最后才会发现出问题\n# 接下来我们需要加载一个预训练的模型和图像处理器 # 这里我们使用的是 Hugging Face 的 transformers 库来加载一个 ViT 模型 # 以及一个图像处理器（image processor）来处理输入的图像 from transformers import AutoImageProcessor model_checkpoint = \"google/vit-base-patch16-224-in21k\" image_processor = AutoImageProcessor.from_pretrained(model_checkpoint, use_fast=True) # 接下来我们加载一个预训练的模型 # 这里我们使用的是 Hugging Face 的 transformers 库来加载一个 ViT 模型 from transformers import AutoModelForImageClassification, TrainingArguments, Trainer model = AutoModelForImageClassification.from_pretrained( model_checkpoint, label2id=label2id, id2label=id2label, ignore_mismatched_sizes=True, # provide this in case you're planning to fine-tune an already fine-tuned checkpoint ) 这里 tutorial 中输入的是 google 的 VIT 模型\n唯一要注意的是这里的 use_fast=True,\n加上之后据说图片的导入能快10x to 30x\nStep4: 加载 Dataset # 导入一些常用的图像处理函数 from torchvision.transforms import ( CenterCrop, Compose, Normalize, RandomHorizontalFlip, RandomResizedCrop, Resize, ToTensor, ) # 接下来我们做一些预处理 # 首先是normalize normalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std) # 然后是train和validation的图像变换 train_transforms = Compose( [ RandomResizedCrop(image_processor.size[\"height\"]), RandomHorizontalFlip(), ToTensor(), normalize, ] ) # validation也是一样的处理 val_transforms = Compose( [ Resize(image_processor.size[\"height\"]), CenterCrop(image_processor.size[\"height\"]), ToTensor(), normalize, ] ) # 然后写一个函数 process dataset def preprocess_train(example_batch): \"\"\"Apply train_transforms across a batch.\"\"\" example_batch[\"pixel_values\"] = [ train_transforms(Image.open(io.BytesIO(image[\"bytes\"])).convert(\"RGB\")) for image in example_batch[\"image\"] ] return example_batch # validation也是一样的处理 def preprocess_val(example_batch): \"\"\"Apply val_transforms across a batch.\"\"\" example_batch[\"pixel_values\"] = [ val_transforms(Image.open(io.BytesIO(image[\"bytes\"])).convert(\"RGB\")) for image in example_batch[\"image\"] ] return example_batch # 接下来我们对数据集进行预处理, 拆分成训练集和验证集 splits = dataset.train_test_split(test_size=0.1) train_ds = splits[\"train\"] val_ds = splits[\"test\"] train_ds = train_ds.cast_column(\"image\", DatasetsImage(decode=False)) val_ds = val_ds.cast_column(\"image\", DatasetsImage(decode=False)) # 然后transform一下 train_ds.set_transform(preprocess_train) val_ds.set_transform(preprocess_val) 这里和其他的模型也没有区别，都是一样的处理方式\n虽然这里看起来很长，但是其实都是 到处copy-paste 🤦‍♂️\nStep 5: 训练前准备 # 这个函数的作用是打印模型的可训练参数和总参数数量 # 这个函数是可以复用的，在这里标记一下 def print_trainable_parameters(model): trainable_params = 0 all_param = 0 for _, param in model.named_parameters(): all_param += param.numel() if param.requires_grad: trainable_params += param.numel() print( f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.2f}\" ) # 加载config from transformers import TrainingArguments, Trainer model_name = model_checkpoint.split(\"/\")[-1] batch_size = 128 args = TrainingArguments( f\"{model_name}-finetuned-lora-food101\", remove_unused_columns=False, eval_strategy=\"epoch\", # 注：这里在 transformers 4.46+ 版本后从 evluation_strategy 改为 eval_strategy save_strategy=\"epoch\", learning_rate=5e-3, per_device_train_batch_size=batch_size, gradient_accumulation_steps=4, per_device_eval_batch_size=batch_size, fp16=True, num_train_epochs=5, logging_steps=10, load_best_model_at_end=True, metric_for_best_model=\"accuracy\", push_to_hub=True, label_names=[\"labels\"], ) # 接下来我们设置LoRA训练参数 from peft import LoraConfig, get_peft_model config = LoraConfig( r=16, lora_alpha=16, target_modules=[\"query\", \"value\"], # 这里的 target_modules 是指我们要对哪些模块进行 LoRA 微调 # 也就是说，我们甚至不是对整个模型的矩阵进行分解 # 而是对模型中的某些特定模块进行分解 # 这里我们选择了 query 和 value 模块 lora_dropout=0.1, bias=\"none\", modules_to_save=[\"classifier\"], # 这里的 modules_to_save 是指我们要保存哪些模块的参数 # 也就是说，我们只保存分类器的参数 # 这样的话，需要训练的参数就会进一步减少 ) import numpy as np import evaluate metric = evaluate.load(\"accuracy\") # 定义计算指标的函数 def compute_metrics(eval_pred): \"\"\"Computes accuracy on a batch of predictions\"\"\" predictions = np.argmax(eval_pred.predictions, axis=1) return metric.compute(predictions=predictions, references=eval_pred.label_ids) # 这个函数是huggingface transformers 中和 pytorch dataloader __getitem__ 方法对应的函数 # 它的作用是将数据集中的每个样本转换为模型可以接受的格式 # 这里我们将图像转换为 pixel_values，并将标签转换为 label def collate_fn(examples): pixel_values = torch.stack([example[\"pixel_values\"] for example in examples]) labels = torch.tensor([example[\"label\"] for example in examples]) return {\"pixel_values\": pixel_values, \"labels\": labels} 训练前准备包括打印参数的辅助函数，以及所有的 hyper_parameters\n还有 evaluation matrix 和 collate_fn 函数\n在这里，这些都是另外定义的，而不是像 pytorch 那样，定义在 class 里的\nStep 6: 定义模型 from transformers import AutoModelForImageClassification, TrainingArguments, Trainer # 首先定义原本的pretrain model model = AutoModelForImageClassification.from_pretrained( model_checkpoint, label2id=label2id, id2label=id2label, ignore_mismatched_sizes=True, # provide this in case you're planning to fine-tune an already fine-tuned checkpoint ) # 打印模型的可训练参数和总参数数量 print_trainable_parameters(model) lora_model = get_peft_model(model, config) print_trainable_parameters(lora_model) 这一步就是把前面的config导入一下，\nTransformer is all you need\nTransformer库中的 AutoModel 会帮你完成一切的\nStep 7: 模型训练 # ok, 现在我们创建一个 Trainer 对象，然后就可以开始训练了 trainer = Trainer( lora_model, args, train_dataset=train_ds, eval_dataset=val_ds, tokenizer=image_processor, compute_metrics=compute_metrics, data_collator=collate_fn, ) # 但是先不着急，我们先看看大模型 zero-shot 的效果如何 print(\"Evaluating the base model without LoRA...\") zero_shot_results = trainer.evaluate(val_ds) print(f\"Zero-shot accuracy: \", zero_shot_results) with open(\"results.txt\", \"w\") as f: f.write(f\"Zero-shot accuracy: {zero_shot_results}\") print(\"Training the model with LoRA...\") train_results = trainer.train() print(\"Evaluating the LoRA model...\") LoRA_results = trainer.evaluate(val_ds) print(f\"LoRA accuracy: \", LoRA_results) with open(\"results.txt\", \"a\") as f: f.write(f\"LoRA accuracy: {LoRA_results}\") 最后就是训练的部分了\n我们只需把 model, datasets, criteria_matrix 和 tokenizer 输入进去就 ok 了\n剩下的 .fit() 和 .evaluate() 会帮我们完成\n最后我们就可以输出结果啦♪\nStep 8: Results origianl model trainable params: 85876325 || all params: 85876325 || trainable%: 100.00 LoRA trainable params: 667493 || all params: 86543818 || trainable%: 0.77 可以看到这里 LoRA 只会训练 0.77% 的参数\nZero-shot accuracy: {'eval_loss': 4.615139007568359, 'eval_model_preparation_time': 0.0094, 'eval_accuracy': 0.01287128712871287, 'eval_runtime': 68.1035, 'eval_samples_per_second': 148.304, 'eval_steps_per_second': 1.16} LoRA accuracy: {'eval_loss': 0.4589368402957916, 'eval_model_preparation_time': 0.0094, 'eval_accuracy': 0.8781188118811881, 'eval_runtime': 60.1694, 'eval_samples_per_second': 167.859, 'eval_steps_per_second': 1.313, 'epoch': 5.0} 但是 LoRA 的效果还是挺好的，准确率从 1.3% -\u003e 87.8%, 提升还是非常明显的\n我这里一共训练了一个小时左右。\npytorch lightning 版本 然后，我看 openpi_pytorch 在用 pytorch lightning, 说是懒人最爱的 AI package, 我就想试试\n省流 总结，pytorch lightning trainer 爆杀了 huggingface trainer\n那么，代价是什么呢\n你需要多写一个 module class 和 dataset class\n甚至 20 行就能搞定\nStep 9: pytorch lightning dataset class 首先，在刚才的代码的基础上，我们先定义一个 dataset:\n# 这里定义一下 Dataset class Food101DataModule(pl.LightningDataModule): def __init__(self, train_ds, val_ds, collate_fn, batch_size): super().__init__() self.train_ds = train_ds self.val_ds = val_ds # collate_fn 相当于__get_item__ self.collate_fn = collate_fn self.batch_size = batch_size def train_dataloader(self): return DataLoader(self.train_ds, batch_size=self.batch_size, shuffle=True, collate_fn=self.collate_fn, num_workers=64, pin_memory=True, prefetch_factor=4) def val_dataloader(self): return DataLoader(self.val_ds, batch_size=self.batch_size, shuffle=False, collate_fn=self.collate_fn, num_workers=64, pin_memory=True, prefetch_factor=4) data_module = Food101DataModule( train_ds=train_ds, val_ds=val_ds, collate_fn=collate_fn, batch_size=args.per_device_train_batch_size, ) 和之前一样，对吧♪\n只不过现在要多写一个 class 而已，其他的都没有变哦♪\nStep 10: pytorch lightning model 然后，我们只需要再写一个 pytorch lightning model 就可以了\n# 定义一下 PyTorch Lightning 模型 # 注：self.log的部分是 wandb 的内容，用于导出log的 class Food101Module(pl.LightningModule): def __init__(self, model, learning_rate, metric, collate_fn): super().__init__() self.model = model self.lr = learning_rate self.metric = metric self.collate_fn = collate_fn # PyTorch Lightning Module 的 forward 方法 def forward(self, pixel_values): # Huggingface 的模型输出的时候会返回一个字典，包含 logits 和其他信息 # 这里我们只需要 logits return self.model(pixel_values).logits def training_step(self, batch, batch_idx): pixel_values = batch[\"pixel_values\"] labels = batch[\"labels\"] logits = self(pixel_values) # 这一句话等价于 logits=self.forward(pixel_values) loss = self.model.compute_loss(labels, logits) if hasattr(self.model, \"compute_loss\") else F.cross_entropy(logits, labels) # self.log(\"train_loss\", loss, on_step=True, on_epoch=True) return loss def validation_step(self, batch, batch_idx): pixel_values = batch[\"pixel_values\"] labels = batch[\"labels\"] logits = self(pixel_values) # also compute and log validation loss loss = F.cross_entropy(logits, labels) # self.log(\"val_loss\", loss, on_epoch=True) preds = torch.argmax(logits, dim=1) acc = self.metric.compute(predictions=preds, references=labels)[\"accuracy\"] # self.log(\"val_acc\", acc, on_epoch=True) def configure_optimizers(self): return torch.optim.AdamW(self.parameters(), lr=self.lr) lightning_module = Food101Module( model=lora_model, learning_rate=args.learning_rate, metric=metric, collate_fn=collate_fn, ) 也和之前一样，不过是要定义一下 forward 和 optimizer 而已\n我认为唯一要注意的点就是：huggingface dataset 会返回的不止是 logits, 还有别的信息\n所以 forward return 的时候只需返回 .logits 即可\nStep 11: train and validation pl_trainer.fit(lightning_module, datamodule=data_module) res = pl_trainer.validate(lightning_module, datamodule=data_module) 没有什么好说的，就是 .fit 和 .validate\nStep 12: 结果 对此，我只能说:\n遥遥领先\n只用了 200 秒钟就完成了1个 epoch + validation\n差不多是hugging face的4.5倍速度。\n总结 测试了一下 pytorch lightning 和 huggingface 的 LoRA 我发现 pytorch lightning 在 CPU IO 瓶颈的情况下的表现显著比 huggingface trainer 要好 $$ \\text{pytorch lightning train 1 epoch} \\approx 2 min \\ \\text{huggingface train 1 epoch} \\approx 12 min \\ \\ \\text{pytorch lightning validation} \\approx 8-10 s \\ \\text{huggingface validation} \\approx 60 s \\ $$ 最后 validation 的结果都是差不多的,但是 pytorch lightning 就是比 huggingface tutorial 要快好几倍\n",
  "wordCount" : "1103",
  "inLanguage": "en",
  "datePublished": "2025-07-11T11:33:41+08:00",
  "dateModified": "2025-07-11T11:33:41+08:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://tzj2006.github.io/bugjournal/2025-07-11/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "TzJ's Net",
    "logo": {
      "@type": "ImageObject",
      "url": "https://tzj2006.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://tzj2006.github.io/" accesskey="h" title="TzJ&#39;s Net (Alt + H)">TzJ&#39;s Net</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://tzj2006.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://tzj2006.github.io/bugjournal/" title="bugJournal">
                    <span>bugJournal</span>
                </a>
            </li>
            <li>
                <a href="https://tzj2006.github.io/leetcode/" title="leetcode">
                    <span>leetcode</span>
                </a>
            </li>
            <li>
                <a href="https://tzj2006.github.io/posts/" title="posts &amp; notes">
                    <span>posts &amp; notes</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://tzj2006.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://tzj2006.github.io/bugjournal/">BugJournals</a></div>
    <h1 class="post-title entry-hint-parent">
      Bug Journal 2025-07-11
    </h1>
    <div class="post-meta"><span title='2025-07-11 11:33:41 +0800 CST'>July 11, 2025</span>&nbsp;·&nbsp;6 min


      
      <div class="meta-item">
        <span id="busuanzi_container_page_pv">
           &nbsp; People Read: <span id="busuanzi_value_page_pv"></span>
        </span>
     </div>

    </div>
  </header> 
  <div class="post-content"><h2 id="lora-finetuning">LoRA finetuning<a hidden class="anchor" aria-hidden="true" href="#lora-finetuning">#</a></h2>
<p>之前一直听说 LoRA 的大名，今天来看看 LoRA 到底在做什么</p>
<p>正好我看到了 huggingface 上有 <a href="https://huggingface.co/docs/peft/main/en/developer_guides/lora">LoRA tutorial</a> 所以就过来研究了一下🧐</p>
<p><em>注：代码顺序与 tutorial中略有出入</em></p>
<p>省流：想看 LoRA specific 的同学请直接从[这里开始看](#Step 5: 训练前准备)</p>
<h4 id="step1-导入需要用到的-package">Step1: 导入需要用到的 package<a hidden class="anchor" aria-hidden="true" href="#step1-导入需要用到的-package">#</a></h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">transformers</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">accelerate</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">peft</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;transformers version: </span><span class="si">{</span><span class="n">transformers</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;accelerate version: </span><span class="si">{</span><span class="n">accelerate</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;torch version: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;peft version: </span><span class="si">{</span><span class="n">peft</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span></code></pre></div><p>需要导入的 package 大概就这么几个，首先是 transformers, accelerate, torch 和 peft</p>
<p>今天这个 LoRA 主要就是用的 peft package.</p>
<p>至于 accelerate, 就是用来加速 peft 的</p>
<h4 id="step2-数据集加载">Step2: 数据集加载<a hidden class="anchor" aria-hidden="true" href="#step2-数据集加载">#</a></h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 接下来加载数据集</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 这里我们使用的是 Hugging Face 的 datasets 库来加载 Food101 数据集</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># dataset = load_dataset(&#34;food101&#34;, split=&#34;train[:5000]&#34;)  # 只加载前5000个样本以加快速度</span>
</span></span><span class="line"><span class="cl"><span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&#34;food101&#34;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&#34;train+validation&#34;</span><span class="p">)</span>  <span class="c1"># 加载整个数据集</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">Image</span> <span class="k">as</span> <span class="n">DatasetsImage</span>
</span></span><span class="line"><span class="cl"><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">cast_column</span><span class="p">(</span><span class="s2">&#34;image&#34;</span><span class="p">,</span> <span class="n">DatasetsImage</span><span class="p">(</span><span class="n">decode</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 然后把标签拿出来</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 这里 huggingface 要求一个 labeltoid &amp; idtolabel</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 所以这里要弄两个 map 互相 map</span>
</span></span><span class="line"><span class="cl"><span class="n">labels</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s2">&#34;label&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">names</span>
</span></span><span class="line"><span class="cl"><span class="n">label2id</span><span class="p">,</span> <span class="n">id2label</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(),</span> <span class="nb">dict</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">labels</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">label2id</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
</span></span><span class="line"><span class="cl">    <span class="n">id2label</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">label</span>
</span></span></code></pre></div><p>这里demo中用的是Food101数据集 (老演员了[doge]),</p>
<p>但是这个作为 classification 的数据集其实不太好（因为食物的种类非常非常多</p>
<p>但是作为LoRA刚刚好，因为LoRA就是专门针对这个事情的</p>
<p>加载这个部分倒是没什么好说的</p>
<p>最后这个 .cast_column 是后来发现这个数据集存的是二进制文件，所以不能 decode (by ChatGPT)</p>
<h4 id="step3-加载预训练模型">Step3: 加载预训练模型<a hidden class="anchor" aria-hidden="true" href="#step3-加载预训练模型">#</a></h4>
<p><strong>这个很重要！！</strong>, 不要到时候跑起来了发现没有导入预训练模型</p>
<p><em>注：如果没有加载预训练模型，不会有<strong>任何 Warning or Error</strong>，什么都可以正常跑，但是跑到最后才会发现出问题</em></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 接下来我们需要加载一个预训练的模型和图像处理器</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 这里我们使用的是 Hugging Face 的 transformers 库来加载一个 ViT 模型</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 以及一个图像处理器（image processor）来处理输入的图像</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoImageProcessor</span>
</span></span><span class="line"><span class="cl"><span class="n">model_checkpoint</span> <span class="o">=</span> <span class="s2">&#34;google/vit-base-patch16-224-in21k&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">image_processor</span> <span class="o">=</span> <span class="n">AutoImageProcessor</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_checkpoint</span><span class="p">,</span> <span class="n">use_fast</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 接下来我们加载一个预训练的模型</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 这里我们使用的是 Hugging Face 的 transformers 库来加载一个 ViT 模型</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForImageClassification</span><span class="p">,</span> <span class="n">TrainingArguments</span><span class="p">,</span> <span class="n">Trainer</span>
</span></span><span class="line"><span class="cl"><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForImageClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">model_checkpoint</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">label2id</span><span class="o">=</span><span class="n">label2id</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">id2label</span><span class="o">=</span><span class="n">id2label</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">ignore_mismatched_sizes</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="c1"># provide this in case you&#39;re planning to fine-tune an already fine-tuned checkpoint</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span></code></pre></div><p>这里 tutorial 中输入的是 google 的 VIT 模型</p>
<p>唯一要注意的是这里的 <code>use_fast=True</code>,</p>
<p>加上之后据说图片的导入能快<code>10x to 30x</code></p>
<h4 id="step4-加载-dataset">Step4: 加载 Dataset<a hidden class="anchor" aria-hidden="true" href="#step4-加载-dataset">#</a></h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 导入一些常用的图像处理函数</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torchvision.transforms</span> <span class="kn">import</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">CenterCrop</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">Compose</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">Normalize</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">RandomHorizontalFlip</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">RandomResizedCrop</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">Resize</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">ToTensor</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 接下来我们做一些预处理</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 首先是normalize</span>
</span></span><span class="line"><span class="cl"><span class="n">normalize</span> <span class="o">=</span> <span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">image_processor</span><span class="o">.</span><span class="n">image_mean</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">image_processor</span><span class="o">.</span><span class="n">image_std</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 然后是train和validation的图像变换</span>
</span></span><span class="line"><span class="cl"><span class="n">train_transforms</span> <span class="o">=</span> <span class="n">Compose</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="p">[</span>
</span></span><span class="line"><span class="cl">        <span class="n">RandomResizedCrop</span><span class="p">(</span><span class="n">image_processor</span><span class="o">.</span><span class="n">size</span><span class="p">[</span><span class="s2">&#34;height&#34;</span><span class="p">]),</span>
</span></span><span class="line"><span class="cl">        <span class="n">RandomHorizontalFlip</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">        <span class="n">ToTensor</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">        <span class="n">normalize</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># validation也是一样的处理</span>
</span></span><span class="line"><span class="cl"><span class="n">val_transforms</span> <span class="o">=</span> <span class="n">Compose</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="p">[</span>
</span></span><span class="line"><span class="cl">        <span class="n">Resize</span><span class="p">(</span><span class="n">image_processor</span><span class="o">.</span><span class="n">size</span><span class="p">[</span><span class="s2">&#34;height&#34;</span><span class="p">]),</span>
</span></span><span class="line"><span class="cl">        <span class="n">CenterCrop</span><span class="p">(</span><span class="n">image_processor</span><span class="o">.</span><span class="n">size</span><span class="p">[</span><span class="s2">&#34;height&#34;</span><span class="p">]),</span>
</span></span><span class="line"><span class="cl">        <span class="n">ToTensor</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">        <span class="n">normalize</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 然后写一个函数 process dataset</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">preprocess_train</span><span class="p">(</span><span class="n">example_batch</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;Apply train_transforms across a batch.&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">example_batch</span><span class="p">[</span><span class="s2">&#34;pixel_values&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
</span></span><span class="line"><span class="cl">        <span class="n">train_transforms</span><span class="p">(</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">image</span><span class="p">[</span><span class="s2">&#34;bytes&#34;</span><span class="p">]))</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s2">&#34;RGB&#34;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">example_batch</span><span class="p">[</span><span class="s2">&#34;image&#34;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">example_batch</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># validation也是一样的处理</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">preprocess_val</span><span class="p">(</span><span class="n">example_batch</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;Apply val_transforms across a batch.&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">example_batch</span><span class="p">[</span><span class="s2">&#34;pixel_values&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
</span></span><span class="line"><span class="cl">        <span class="n">val_transforms</span><span class="p">(</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">image</span><span class="p">[</span><span class="s2">&#34;bytes&#34;</span><span class="p">]))</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s2">&#34;RGB&#34;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">example_batch</span><span class="p">[</span><span class="s2">&#34;image&#34;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">example_batch</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 接下来我们对数据集进行预处理, 拆分成训练集和验证集</span>
</span></span><span class="line"><span class="cl"><span class="n">splits</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">train_ds</span> <span class="o">=</span> <span class="n">splits</span><span class="p">[</span><span class="s2">&#34;train&#34;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">val_ds</span> <span class="o">=</span> <span class="n">splits</span><span class="p">[</span><span class="s2">&#34;test&#34;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">train_ds</span> <span class="o">=</span> <span class="n">train_ds</span><span class="o">.</span><span class="n">cast_column</span><span class="p">(</span><span class="s2">&#34;image&#34;</span><span class="p">,</span> <span class="n">DatasetsImage</span><span class="p">(</span><span class="n">decode</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">val_ds</span> <span class="o">=</span> <span class="n">val_ds</span><span class="o">.</span><span class="n">cast_column</span><span class="p">(</span><span class="s2">&#34;image&#34;</span><span class="p">,</span> <span class="n">DatasetsImage</span><span class="p">(</span><span class="n">decode</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 然后transform一下</span>
</span></span><span class="line"><span class="cl"><span class="n">train_ds</span><span class="o">.</span><span class="n">set_transform</span><span class="p">(</span><span class="n">preprocess_train</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">val_ds</span><span class="o">.</span><span class="n">set_transform</span><span class="p">(</span><span class="n">preprocess_val</span><span class="p">)</span>
</span></span></code></pre></div><p>这里和其他的模型也没有区别，都是一样的处理方式</p>
<p>虽然这里看起来很长，但是其实都是 到处copy-paste 🤦‍♂️</p>
<h4 id="step-5-训练前准备">Step 5: 训练前准备<a hidden class="anchor" aria-hidden="true" href="#step-5-训练前准备">#</a></h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 这个函数的作用是打印模型的可训练参数和总参数数量</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 这个函数是可以复用的，在这里标记一下</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">print_trainable_parameters</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">trainable_params</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">    <span class="n">all_param</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">        <span class="n">all_param</span> <span class="o">+=</span> <span class="n">param</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">trainable_params</span> <span class="o">+=</span> <span class="n">param</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="sa">f</span><span class="s2">&#34;trainable params: </span><span class="si">{</span><span class="n">trainable_params</span><span class="si">}</span><span class="s2"> || all params: </span><span class="si">{</span><span class="n">all_param</span><span class="si">}</span><span class="s2"> || trainable%: </span><span class="si">{</span><span class="mi">100</span> <span class="o">*</span> <span class="n">trainable_params</span> <span class="o">/</span> <span class="n">all_param</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl"><span class="c1"># 加载config</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span><span class="p">,</span> <span class="n">Trainer</span>
</span></span><span class="line"><span class="cl"><span class="n">model_name</span> <span class="o">=</span> <span class="n">model_checkpoint</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&#34;/&#34;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
</span></span><span class="line"><span class="cl"><span class="n">args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="sa">f</span><span class="s2">&#34;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">-finetuned-lora-food101&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">remove_unused_columns</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">&#34;epoch&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 注：这里在 transformers 4.46+ 版本后从 evluation_strategy 改为 eval_strategy</span>
</span></span><span class="line"><span class="cl">    <span class="n">save_strategy</span><span class="o">=</span><span class="s2">&#34;epoch&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">5e-3</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">logging_steps</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">metric_for_best_model</span><span class="o">=</span><span class="s2">&#34;accuracy&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">label_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&#34;labels&#34;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 接下来我们设置LoRA训练参数</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">peft</span> <span class="kn">import</span> <span class="n">LoraConfig</span><span class="p">,</span> <span class="n">get_peft_model</span>
</span></span><span class="line"><span class="cl"><span class="n">config</span> <span class="o">=</span> <span class="n">LoraConfig</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">r</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">lora_alpha</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">target_modules</span><span class="o">=</span><span class="p">[</span><span class="s2">&#34;query&#34;</span><span class="p">,</span> <span class="s2">&#34;value&#34;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 这里的 target_modules 是指我们要对哪些模块进行 LoRA 微调</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 也就是说，我们甚至不是对整个模型的矩阵进行分解</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 而是对模型中的某些特定模块进行分解</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 这里我们选择了 query 和 value 模块</span>
</span></span><span class="line"><span class="cl">    <span class="n">lora_dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">bias</span><span class="o">=</span><span class="s2">&#34;none&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">modules_to_save</span><span class="o">=</span><span class="p">[</span><span class="s2">&#34;classifier&#34;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 这里的 modules_to_save 是指我们要保存哪些模块的参数</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 也就是说，我们只保存分类器的参数</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 这样的话，需要训练的参数就会进一步减少</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">evaluate</span>
</span></span><span class="line"><span class="cl"><span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&#34;accuracy&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 定义计算指标的函数</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">compute_metrics</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;Computes accuracy on a batch of predictions&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">eval_pred</span><span class="o">.</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">eval_pred</span><span class="o">.</span><span class="n">label_ids</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 这个函数是huggingface transformers 中和 pytorch dataloader __getitem__ 方法对应的函数</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 它的作用是将数据集中的每个样本转换为模型可以接受的格式</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 这里我们将图像转换为 pixel_values，并将标签转换为 label</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">collate_fn</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">pixel_values</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">example</span><span class="p">[</span><span class="s2">&#34;pixel_values&#34;</span><span class="p">]</span> <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">example</span><span class="p">[</span><span class="s2">&#34;label&#34;</span><span class="p">]</span> <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="p">{</span><span class="s2">&#34;pixel_values&#34;</span><span class="p">:</span> <span class="n">pixel_values</span><span class="p">,</span> <span class="s2">&#34;labels&#34;</span><span class="p">:</span> <span class="n">labels</span><span class="p">}</span>
</span></span></code></pre></div><p>训练前准备包括打印参数的辅助函数，以及所有的 hyper_parameters</p>
<p>还有 evaluation matrix 和 collate_fn 函数</p>
<p>在这里，这些都是另外定义的，而不是像 pytorch 那样，定义在 class 里的</p>
<h4 id="step-6-定义模型">Step 6: 定义模型<a hidden class="anchor" aria-hidden="true" href="#step-6-定义模型">#</a></h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForImageClassification</span><span class="p">,</span> <span class="n">TrainingArguments</span><span class="p">,</span> <span class="n">Trainer</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 首先定义原本的pretrain model</span>
</span></span><span class="line"><span class="cl"><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForImageClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">model_checkpoint</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">label2id</span><span class="o">=</span><span class="n">label2id</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">id2label</span><span class="o">=</span><span class="n">id2label</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">ignore_mismatched_sizes</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="c1"># provide this in case you&#39;re planning to fine-tune an already fine-tuned checkpoint</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 打印模型的可训练参数和总参数数量</span>
</span></span><span class="line"><span class="cl"><span class="n">print_trainable_parameters</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">lora_model</span> <span class="o">=</span> <span class="n">get_peft_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">print_trainable_parameters</span><span class="p">(</span><span class="n">lora_model</span><span class="p">)</span>
</span></span></code></pre></div><p>这一步就是把前面的config导入一下，</p>
<p><del>Transformer is all you need</del></p>
<p>Transformer库中的 AutoModel 会帮你完成一切的</p>
<h4 id="step-7-模型训练">Step 7: 模型训练<a hidden class="anchor" aria-hidden="true" href="#step-7-模型训练">#</a></h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># ok, 现在我们创建一个 Trainer 对象，然后就可以开始训练了</span>
</span></span><span class="line"><span class="cl"><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">lora_model</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">args</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_ds</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">eval_dataset</span><span class="o">=</span><span class="n">val_ds</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">tokenizer</span><span class="o">=</span><span class="n">image_processor</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">data_collator</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 但是先不着急，我们先看看大模型 zero-shot 的效果如何</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Evaluating the base model without LoRA...&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">zero_shot_results</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">val_ds</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Zero-shot accuracy: &#34;</span><span class="p">,</span> <span class="n">zero_shot_results</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&#34;results.txt&#34;</span><span class="p">,</span> <span class="s2">&#34;w&#34;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Zero-shot accuracy: </span><span class="si">{</span><span class="n">zero_shot_results</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Training the model with LoRA...&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">train_results</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Evaluating the LoRA model...&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">LoRA_results</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">val_ds</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;LoRA accuracy: &#34;</span><span class="p">,</span> <span class="n">LoRA_results</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&#34;results.txt&#34;</span><span class="p">,</span> <span class="s2">&#34;a&#34;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;LoRA accuracy: </span><span class="si">{</span><span class="n">LoRA_results</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span></code></pre></div><p>最后就是训练的部分了</p>
<p>我们只需把 model, datasets, criteria_matrix 和 tokenizer 输入进去就 ok 了</p>
<p>剩下的 <code>.fit()</code> 和 <code>.evaluate()</code> 会帮我们完成</p>
<p>最后我们就可以输出结果啦♪</p>
<h4 id="step-8-results">Step 8: Results<a hidden class="anchor" aria-hidden="true" href="#step-8-results">#</a></h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-markdown" data-lang="markdown"><span class="line"><span class="cl">origianl model trainable params: 85876325 || all params: 85876325 || trainable%: 100.00
</span></span><span class="line"><span class="cl">LoRA trainable params: 667493 || all params: 86543818 || trainable%: 0.77
</span></span></code></pre></div><p>可以看到这里 LoRA 只会训练 0.77% 的参数</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">Zero-shot accuracy</span><span class="p">:</span><span class="w"> </span>{<span class="nt">&#39;eval_loss&#39;: 4.615139007568359, &#39;eval_model_preparation_time&#39;: 0.0094, &#39;eval_accuracy&#39;: 0.01287128712871287, &#39;eval_runtime&#39;: 68.1035, &#39;eval_samples_per_second&#39;: 148.304, &#39;eval_steps_per_second&#39;</span><span class="p">:</span><span class="w"> </span><span class="m">1.16</span>}<span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">LoRA accuracy</span><span class="p">:</span><span class="w"> </span>{<span class="nt">&#39;eval_loss&#39;: 0.4589368402957916, &#39;eval_model_preparation_time&#39;: 0.0094, &#39;eval_accuracy&#39;: 0.8781188118811881, &#39;eval_runtime&#39;: 60.1694, &#39;eval_samples_per_second&#39;: 167.859, &#39;eval_steps_per_second&#39;: 1.313, &#39;epoch&#39;</span><span class="p">:</span><span class="w"> </span><span class="m">5.0</span>}<span class="w">
</span></span></span></code></pre></div><p>但是 LoRA 的效果还是挺好的，准确率从 1.3% -&gt; 87.8%, 提升还是非常明显的</p>
<p>我这里一共训练了一个小时左右。</p>
<p><img alt="image-20250711122527798" loading="lazy" src="https://tzj2006.github.io/images/2025-07-11/image-20250711122527798.png"></p>
<h3 id="pytorch-lightning-版本">pytorch lightning 版本<a hidden class="anchor" aria-hidden="true" href="#pytorch-lightning-版本">#</a></h3>
<p>然后，我看 <a href="https://github.com/ZibinDong/openpi_pytorch">openpi_pytorch</a> 在用 pytorch lightning, 说是懒人最爱的 AI package, 我就想试试</p>
<h4 id="省流">省流<a hidden class="anchor" aria-hidden="true" href="#省流">#</a></h4>
<p>总结，pytorch lightning trainer 爆杀了 huggingface trainer</p>
<hr>
<p><del>那么，代价是什么呢</del></p>
<p>你需要多写一个 module class 和 dataset class</p>
<p>甚至 20 行就能搞定</p>
<h4 id="step-9-pytorch-lightning-dataset-class">Step 9: pytorch lightning dataset class<a hidden class="anchor" aria-hidden="true" href="#step-9-pytorch-lightning-dataset-class">#</a></h4>
<p>首先，在刚才的代码的基础上，我们先定义一个 dataset:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 这里定义一下 Dataset</span>
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Food101DataModule</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">LightningDataModule</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_ds</span><span class="p">,</span> <span class="n">val_ds</span><span class="p">,</span> <span class="n">collate_fn</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">train_ds</span> <span class="o">=</span> <span class="n">train_ds</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">val_ds</span> <span class="o">=</span> <span class="n">val_ds</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># collate_fn 相当于__get_item__</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">collate_fn</span> <span class="o">=</span> <span class="n">collate_fn</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">train_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_ds</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">collate_fn</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">prefetch_factor</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">val_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">val_ds</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">collate_fn</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">prefetch_factor</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl"><span class="n">data_module</span> <span class="o">=</span> <span class="n">Food101DataModule</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">train_ds</span><span class="o">=</span><span class="n">train_ds</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">val_ds</span><span class="o">=</span><span class="n">val_ds</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">per_device_train_batch_size</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span></code></pre></div><p>和之前一样，对吧♪</p>
<p>只不过现在要多写一个 class 而已，其他的都没有变哦♪</p>
<h4 id="step-10-pytorch-lightning-model">Step 10: pytorch lightning model<a hidden class="anchor" aria-hidden="true" href="#step-10-pytorch-lightning-model">#</a></h4>
<p>然后，我们只需要再写一个 pytorch lightning model 就可以了</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 定义一下 PyTorch Lightning 模型</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 注：self.log的部分是 wandb 的内容，用于导出log的</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Food101Module</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">LightningModule</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">metric</span><span class="p">,</span> <span class="n">collate_fn</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">learning_rate</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">metric</span> <span class="o">=</span> <span class="n">metric</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">collate_fn</span> <span class="o">=</span> <span class="n">collate_fn</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># PyTorch Lightning Module 的 forward 方法</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pixel_values</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># Huggingface 的模型输出的时候会返回一个字典，包含 logits 和其他信息</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 这里我们只需要 logits</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">pixel_values</span><span class="p">)</span><span class="o">.</span><span class="n">logits</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">pixel_values</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&#34;pixel_values&#34;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&#34;labels&#34;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">pixel_values</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 这一句话等价于 logits=self.forward(pixel_values)</span>
</span></span><span class="line"><span class="cl">        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">compute_loss</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">logits</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&#34;compute_loss&#34;</span><span class="p">)</span> <span class="k">else</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># self.log(&#34;train_loss&#34;, loss, on_step=True, on_epoch=True)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">loss</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">pixel_values</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&#34;pixel_values&#34;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&#34;labels&#34;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">pixel_values</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># also compute and log validation loss</span>
</span></span><span class="line"><span class="cl">        <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># self.log(&#34;val_loss&#34;, loss, on_epoch=True)</span>
</span></span><span class="line"><span class="cl">        <span class="n">preds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">acc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">preds</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)[</span><span class="s2">&#34;accuracy&#34;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># self.log(&#34;val_acc&#34;, acc, on_epoch=True)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      
</span></span><span class="line"><span class="cl"><span class="n">lightning_module</span> <span class="o">=</span> <span class="n">Food101Module</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">=</span><span class="n">lora_model</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">learning_rate</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">metric</span><span class="o">=</span><span class="n">metric</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span></code></pre></div><p>也和之前一样，不过是要定义一下 forward 和 optimizer 而已</p>
<p>我认为唯一要注意的点就是：huggingface dataset 会返回的不止是 logits, 还有别的信息</p>
<p>所以 forward return 的时候只需返回 <code>.logits</code> 即可</p>
<h4 id="step-11-train-and-validation">Step 11: train and validation<a hidden class="anchor" aria-hidden="true" href="#step-11-train-and-validation">#</a></h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">pl_trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">lightning_module</span><span class="p">,</span> <span class="n">datamodule</span><span class="o">=</span><span class="n">data_module</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">res</span> <span class="o">=</span> <span class="n">pl_trainer</span><span class="o">.</span><span class="n">validate</span><span class="p">(</span><span class="n">lightning_module</span><span class="p">,</span> <span class="n">datamodule</span><span class="o">=</span><span class="n">data_module</span><span class="p">)</span>
</span></span></code></pre></div><p>没有什么好说的，就是 <code>.fit</code> 和 <code>.validate</code></p>
<h4 id="step-12-结果">Step 12: 结果<a hidden class="anchor" aria-hidden="true" href="#step-12-结果">#</a></h4>
<p><img alt="image-20250711142208300" loading="lazy" src="https://tzj2006.github.io/images/2025-07-11/image-20250711142208300.png"></p>
<p>对此，我只能说:</p>
<p><strong>遥遥领先</strong></p>
<p>只用了 200 秒钟就完成了1个 epoch + validation</p>
<p>差不多是hugging face的4.5倍速度。</p>
<h4 id="总结">总结<a hidden class="anchor" aria-hidden="true" href="#总结">#</a></h4>
<p>测试了一下 pytorch lightning 和 huggingface 的 LoRA
我发现 pytorch lightning 在 CPU IO 瓶颈的情况下的表现显著比 huggingface trainer 要好
$$
\text{pytorch lightning train 1 epoch} \approx 2 min \
\text{huggingface train 1 epoch} \approx 12 min \
\
\text{pytorch lightning validation} \approx 8-10 s \
\text{huggingface validation} \approx 60 s \
$$
最后 validation 的结果都是差不多的,但是 pytorch lightning 就是比 huggingface tutorial 要快好几倍</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://tzj2006.github.io/">TzJ&#39;s Net</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
    <span>
        · 本站访客数：<span id="busuanzi_value_site_uv"></span>
        · 总访问量：<span id="busuanzi_value_site_pv"></span>
    </span>
    
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
